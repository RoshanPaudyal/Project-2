{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "193018c6",
   "metadata": {},
   "source": [
    "## Machine learning to create a Trading Algorithim\n",
    "\n",
    "In this project We are trying to predict the buy and sell price for APPL using ML by using lots of variable that can impact prediction. We are aming to achive a average score that is highet then random guessig."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7464caf2-bf55-4749-bb73-158d8402914d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing Required Libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from finta import TA\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas.tseries.offsets import DateOffset\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os \n",
    "from datetime import datetime, timedelta\n",
    "from dotenv import load_dotenv\n",
    "from alpaca_trade_api.rest import REST, TimeFrameUnit, TimeFrame\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "782a3b6f",
   "metadata": {},
   "source": [
    "Setting up API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc5cc510",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "('Key ID must be given to access Alpaca trade API', ' (env: APCA_API_KEY_ID)')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/w4/lsgx7ykn35x5549kp8vwtzcr0000gn/T/ipykernel_91264/1103492019.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0malpaca_api_key\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0malpaca_secret_key\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     api_version=\"v2\")\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/envs/dev/lib/python3.7/site-packages/alpaca_trade_api/rest.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, key_id, secret_key, base_url, api_version, oauth, raw_data)\u001b[0m\n\u001b[1;32m    167\u001b[0m         \"\"\"\n\u001b[1;32m    168\u001b[0m         self._key_id, self._secret_key, self._oauth = get_credentials(\n\u001b[0;32m--> 169\u001b[0;31m             key_id, secret_key, oauth)\n\u001b[0m\u001b[1;32m    170\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_base_url\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mURL\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mURL\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_url\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mget_base_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api_version\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_api_version\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapi_version\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/dev/lib/python3.7/site-packages/alpaca_trade_api/common.py\u001b[0m in \u001b[0;36mget_credentials\u001b[0;34m(key_id, secret_key, oauth)\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mkey_id\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0moauth\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         raise ValueError('Key ID must be given to access Alpaca trade API',\n\u001b[0;32m---> 85\u001b[0;31m                          ' (env: APCA_API_KEY_ID)')\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0msecret_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msecret_key\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'APCA_API_SECRET_KEY'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: ('Key ID must be given to access Alpaca trade API', ' (env: APCA_API_KEY_ID)')"
     ]
    }
   ],
   "source": [
    "load_dotenv()\n",
    "#Set API and secret key\n",
    "alpaca_api_key = os.getenv(\"ALPACA_API_KEY\")\n",
    "alpaca_secret_key = os.getenv(\"ALPACA_SECRET_KEY\")\n",
    "\n",
    "# Create the Alpaca API object\n",
    "api = REST(\n",
    "    alpaca_api_key,\n",
    "    alpaca_secret_key,\n",
    "    api_version=\"v2\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3f217111",
   "metadata": {},
   "source": [
    "Setting API Parameters to download sticker date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf86569",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Selecting ticker\n",
    "ticker = \"AAPL\"\n",
    "\n",
    "#Set timeframe\n",
    "timeframe = TimeFrame(15, TimeFrameUnit.Minute)\n",
    "\n",
    "#Setting date for latest date available from APIO\n",
    "now = pd.Timestamp(datetime.now().date() - timedelta(days=2))\n",
    "\n",
    "#Caculate the start date \n",
    "start_date = (now - timedelta(days=365*10)).date().isoformat()\n",
    "\n",
    "#Downloading historial data from API\n",
    "df_ticker = api.get_bars(\n",
    "    ticker,\n",
    "    timeframe,\n",
    "    start=start_date,\n",
    ").df\n",
    "\n",
    "# Rename index to \"Date\"\n",
    "df_ticker.index.name = 'Date'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd39f806",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97eeabb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ticker.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d7bdb205",
   "metadata": {},
   "source": [
    "### Generating the Technical Indicators and Custom trading signals by the help of the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf6f3875",
   "metadata": {},
   "outputs": [],
   "source": [
    "indicators_df = pd.DataFrame()\n",
    "\n",
    "indicators_df['Close'] = df_ticker['close']\n",
    "\n",
    "# Calculate daily returns\n",
    "indicators_df['Actual Returns'] = df_ticker['close'].pct_change()\n",
    "\n",
    "#defining short and long window to caculaute EMA\n",
    "short_window = 100\n",
    "long_window = 200\n",
    "\n",
    "# Caulcualating the EMA technical indicators for the short and long windows\n",
    "indicators_df[\"Short\"] = TA.EMA(df_ticker, short_window)\n",
    "indicators_df[\"Long\"] = TA.EMA(df_ticker, long_window)\n",
    "\n",
    "#Caculuating the RSI indicator\n",
    "indicators_df[\"RSI\"] = TA.RSI(df_ticker)\n",
    "\n",
    "# Calculate the upper and lower Bollinger Bands\n",
    "indicators_df['20 Day MA'] = df_ticker['close'].rolling(window=20).mean()\n",
    "indicators_df['Upper Band'] = indicators_df['20 Day MA'] + 2 * df_ticker['close'].rolling(window=20).std()\n",
    "indicators_df['Lower Band'] = indicators_df['20 Day MA'] - 2 * df_ticker['close'].rolling(window=20).std()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7aa9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "indicators_df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "029acc71",
   "metadata": {},
   "source": [
    "#### Finding the correalation between the variables\n",
    "\n",
    "Here we are performing the correlation matrix and visualizing them on a heat map to figure out whcih variables are less correlated.\n",
    "\n",
    "If the correaltion:\n",
    "- Is between 0.0 and -0.3, they have a week correlation.\n",
    "- Is between -0.3 and -0.5 they have a moderate correlation.\n",
    "- Is between 0.5 and -1 they have a high correlation.\n",
    "- is between 0.0 and 0.3 they have a week correlation.\n",
    "- Is between 0.3 and 0.5 they have a moderate correlation.\n",
    "- Is between0.5 and 1 they have a high correlation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdbfe51a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the correlation matrix\n",
    "corr_matrix = indicators_df.dropna().corr()\n",
    "\n",
    "# Generate the heatmap\n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "sns.heatmap(\n",
    "    corr_matrix,\n",
    "    annot=True, \n",
    "    cmap='coolwarm',\n",
    "    ax=ax\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a408817a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trading Rules - buy, hold, and sell signals based on the RSI indicator\n",
    "for i, row in indicators_df.iterrows():\n",
    "    # Buy Signal\n",
    "    if indicators_df.loc[i, 'RSI'] < 30:\n",
    "        indicators_df.loc[i, 'Buy Signal'] = 1\n",
    "    # Sell Signal\n",
    "    elif indicators_df.loc[i, 'RSI'] > 70:\n",
    "        indicators_df.loc[i, 'Buy Signal'] = -1\n",
    "    else:\n",
    "        # Hold\n",
    "        indicators_df.loc[i, 'Buy Signal'] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b30e6c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Count buy, sell and hold values\n",
    "indicators_df['Buy Signal'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a4d5b6-ac52-45cd-ae1f-d21f66f0525f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise Backtest Peformance\n",
    "\n",
    "# Plot the Close price and the Bollinger Bands\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.plot(indicators_df['Close'])\n",
    "plt.plot(indicators_df['RSI'])\n",
    "\n",
    "# Plot the signals\n",
    "plt.plot(indicators_df[indicators_df['Buy Signal'] == 1.0].index, \n",
    "         indicators_df['Close'][indicators_df['Buy Signal'] == 1.0],\n",
    "         '^', markersize=1, color='green', label='Buy')\n",
    "plt.plot(indicators_df[indicators_df['Buy Signal'] == -1.0].index, \n",
    "         indicators_df['Close'][indicators_df['Buy Signal'] == -1.0], \n",
    "         'v', markersize=1, color='red', label='Sell')\n",
    "\n",
    "plt.title('Stock Prices with RSI and Trading Signals')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Price')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "71a12d4f",
   "metadata": {},
   "source": [
    "Theoretical Stock Price Predictions - Caculating return. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb498ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new DataFrame with only the 'Close' column\n",
    "appl_df = df_ticker[['close']].copy()\n",
    "\n",
    "# Reindex using business days frequency\n",
    "appl_df = appl_df.reindex(pd.bdate_range(start=df_ticker.index.min().date(), end=datetime.now().date(), freq='B'))\n",
    "\n",
    "# Review the DataFrame\n",
    "appl_df.tail()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e206f127",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c7a813",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize trade_type column for buys and sells\n",
    "appl_df['trade_type'] = np.nan\n",
    "\n",
    "# Initialize variable to hold the previous_price\n",
    "previous_price = 0\n",
    "\n",
    "# Initialize a cost/proceeds column for recording trade metrics\n",
    "appl_df[\"cost/proceeds\"] = np.nan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a14686b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize share_size equals 100 and accumulated_shares equals 0\n",
    "share_size = 100\n",
    "accumulated_shares = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f130e9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through the Pandas DataFrame and code the conditions of the trading strategy\n",
    "for index, row in appl_df.iterrows():\n",
    "\n",
    "    # buy if the previous price is 0, in other words, buy on the first day\n",
    "    # set the cost/proceeds column equal to the negative value of the row close price\n",
    "    # multiplied by the share_size\n",
    "    if previous_price == 0:\n",
    "        if indicators_df.loc[index, 'RSI'] < 30:\n",
    "            appl_df.loc[index, \"cost/proceeds\"] = -(row[\"close\"] * share_size)\n",
    "            accumulated_shares += share_size\n",
    "            print(f\"{index}: Bought {share_size} shares, total {accumulated_shares}\")\n",
    "\n",
    "    # buy if the current day price is less than the previous day price\n",
    "    # set the cost/proceeds column equal to the negative value of the row close price\n",
    "    # multiplied by the share_size\n",
    "    elif row[\"close\"] < previous_price:\n",
    "        if indicators_df.loc[index, 'RSI'] < 30:\n",
    "            appl_df.loc[index, \"cost/proceeds\"] = -(row[\"close\"] * share_size)\n",
    "            accumulated_shares += share_size\n",
    "            print(f\"{index}: Bought {share_size} shares, total {accumulated_shares}\")\n",
    "\n",
    "    # sell if the current day price is greater than the previous day price\n",
    "    elif row[\"close\"] > previous_price and accumulated_shares > 0 and index != appl_df.index[-1]:\n",
    "        if indicators_df.loc[index, 'RSI'] > 70:\n",
    "            appl_df.loc[index, \"cost/proceeds\"] = row[\"close\"] * share_size\n",
    "            print(f\"{index}: Sold {accumulated_shares} shares\")\n",
    "            accumulated_shares -= share_size\n",
    "            # accumulated_shares = 0\n",
    "\n",
    "    # else hold if the current day price is equal to the previous day price\n",
    "    else:\n",
    "        appl_df.loc[index, \"trade_type\"] = \"hold\"\n",
    "\n",
    "    # set the previous_price variable to the close price of the current row\n",
    "    previous_price = row[\"close\"]\n",
    "\n",
    "    # if the index is the last index of the Dataframe, sell\n",
    "    # set the cost/proceeds column equal to the row close price multiplied\n",
    "    # by the accumulated_shares\n",
    "    if index == appl_df.index[-1]:\n",
    "        appl_df.loc[index, \"trade_type\"] = \"sell\"\n",
    "        appl_df.loc[index, \"cost/proceeds\"] = row[\"close\"] * accumulated_shares\n",
    "        print(f\"{index}: Sold {accumulated_shares} shares\")\n",
    "        accumulated_shares = 0\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "61769a5a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c669bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the return on investment (ROI)\n",
    "roi = round((total_profit_loss / -(invested_capital)) * 100, 2)\n",
    "\n",
    "# Print the ROI\n",
    "print(f\"The trading algorithm resulted in a return on investment of {roi}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf7bf20",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03501b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "indicators_df['Strategy Returns'] = indicators_df['Actual Returns'] * indicators_df['Buy Signal'].shift()\n",
    "indicators_df = indicators_df.dropna()\n",
    "\n",
    "display(indicators_df.head())\n",
    "display(indicators_df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ec2ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "(1 + indicators_df['Strategy Returns']).cumprod().plot()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8ca68cc3",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980b401d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign a copy of the RSI columns to a features DataFrame called X \n",
    "X = indicators_df[['RSI']].shift().dropna()\n",
    "\n",
    "# Assign Buy Signals columns to a features DataFrame called Y\n",
    "y = indicators_df['Buy Signal']\n",
    "display(X.head())\n",
    "display(y.value_counts())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "68a51c00",
   "metadata": {},
   "source": [
    "### Split the data into training and testing using time series split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c3da19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the start of the training period\n",
    "training_begin = X.index.min()\n",
    "\n",
    "# Select the ending period for the training data with an offset of 12 months\n",
    "training_end = X.index.min() + DateOffset(months=12)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25663fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the X_train and y_train DataFrames\n",
    "X_train = X.loc[training_begin:training_end]\n",
    "y_train = y.loc[training_begin:training_end]\n",
    "\n",
    "# Review the X_train DataFrame\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d39863a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the X_test and y_test DataFrames\n",
    "X_test = X.loc[training_end+DateOffset(hours=1):]\n",
    "y_test = y.loc[training_end+DateOffset(hours=1):]\n",
    "\n",
    "# Review the X_test DataFrame\n",
    "X_test.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ff320fcd",
   "metadata": {},
   "source": [
    "Scacling the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bfa86bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Scale the features DataFrames\n",
    "\n",
    "# Create a StandardScaler instance\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Apply the scaler model to fit the X-train data\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Transform the X_train and X_test DataFrames using the X_scaler\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2b3e8dea",
   "metadata": {},
   "source": [
    "As we want to predictBuy/sell Signal, we will go ahead with the classification approach and use SVC classifier from SKLearns Ssupport vector machine (SVM) learning method o fit the training data and make predictions based on the testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b8bfe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From SVM, instantiate SVC classifier model instance\n",
    "svm_model = SVC()\n",
    " \n",
    "# Fit the model to the data using the training data\n",
    "svm_model = svm_model.fit(X_train_scaled, y_train)\n",
    " \n",
    "# Use the testing data to make the model predictions\n",
    "svm_pred = svm_model.predict(X_train_scaled)\n",
    "\n",
    "# Review the model's predicted values\n",
    "print(svm_pred)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "88b6451b",
   "metadata": {},
   "source": [
    "#### Review the classification report associated with the `SVC` model predictions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465bdc1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a classification report to evaluate the model using the predictions and testing data\n",
    "svm_testing_report = classification_report(y_train, svm_pred)\n",
    "\n",
    "# Print the classification report\n",
    "print(svm_testing_report)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "753ed00b",
   "metadata": {},
   "source": [
    "#### Create a predictions DataFrame that contains columns for “Predicted” values, “Actual Returns”, and “Strategy Returns”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9519108",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new empty predictions DataFrame:\n",
    "\n",
    "# Create a predictions DataFrame\n",
    "predictions_df = pd.DataFrame(index=y_train.index)\n",
    "\n",
    "# Add the SVM model predictions to the DataFrame\n",
    "predictions_df['Predicted'] = svm_pred\n",
    "\n",
    "# Add the actual returns to the DataFrame\n",
    "predictions_df['Actual Returns'] = y_train\n",
    "\n",
    "# Add the strategy returns to the DataFrame\n",
    "predictions_df['Strategy Returns'] = predictions_df['Actual Returns'] * predictions_df['Predicted']\n",
    "\n",
    "# Review the DataFrame\n",
    "display(predictions_df.head())\n",
    "display(predictions_df.tail())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2f85fda7",
   "metadata": {},
   "source": [
    "#### Create a cumulative return plot that shows the actual returns vs. the strategy returns. Save a PNG image of this plot. This will serve as a baseline against which to compare the effects of tuning the trading algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91279c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the actual returns versus the strategy returns\n",
    "((1 + predictions_df[['Actual Returns', 'Strategy Returns']]\n",
    "  .cumsum())\n",
    " .plot(figsize=(15, 8)))\n",
    "plt.title('Actual vs. Strategy Returns')\n",
    "plt.show()\n",
    "\n",
    "plt.savefig('Actual vs. Strategy Returns.png')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "296584b0",
   "metadata": {},
   "source": [
    "#### Backtesting a Machine Learning Trading Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a178ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the trained model to predict the trading signals for the testing data.\n",
    "testing_signal_predictions = svm_model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "607c83ee-8b47-4d0e-add5-d6d636916bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model's ability to predict the trading signal for the testing data\n",
    "testing_report = classification_report(y_test, testing_signal_predictions)\n",
    "\n",
    "# Display the report\n",
    "print(testing_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a84a87e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dd6be7f3",
   "metadata": {},
   "source": [
    "#### Create a predictions DataFrame from back testing that contains columns for “Predicted” values, “Actual Returns”, and “Strategy Returns”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee05bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new empty predictions DataFrame:\n",
    "\n",
    "# Create a predictions DataFrame\n",
    "backtest_predictions_df = pd.DataFrame(index=y_test.index)\n",
    "\n",
    "# Add the SVM model predictions to the DataFrame\n",
    "backtest_predictions_df['Predicted'] = testing_signal_predictions\n",
    "\n",
    "# Add the actual returns to the DataFrame\n",
    "backtest_predictions_df['Actual Returns'] = y_test\n",
    "\n",
    "# Add the strategy returns to the DataFrame\n",
    "backtest_predictions_df['Strategy Returns'] = backtest_predictions_df['Actual Returns'] * backtest_predictions_df['Predicted']\n",
    "\n",
    "# Review the DataFrame\n",
    "display(backtest_predictions_df.head())\n",
    "display(backtest_predictions_df.tail())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c2e6b24d",
   "metadata": {},
   "source": [
    "#### Create a cumulative return plot that shows the backtested actual returns vs. the strategy returns. Save a PNG image of this plot. This will serve as a baseline against which to compare the effects of tuning the trading algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37def219",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the actual returns versus the strategy returns\n",
    "((1 + backtest_predictions_df[['Actual Returns', 'Strategy Returns']]\n",
    "  .cumsum())\n",
    " .plot(figsize=(15, 8)))\n",
    "plt.title('Back Tested Actual vs. Strategy Returns')\n",
    "plt.show()\n",
    "\n",
    "# plt.savefig('Back Tested Actual vs. Strategy Returns')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "34a360f4",
   "metadata": {},
   "source": [
    "### Tune the Baseline Trading Algorithm Using Alternative ML Model - I am still working on This Asha I have not finished.\n",
    "\n",
    "In this section, you’ll tune, or adjust, the model’s input features to find the parameters that result in the best trading outcomes. You’ll choose the best by comparing the cumulative products of the strategy returns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a6735c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Define the period for training and testing datasets\n",
    "# training_period = 300 # number of days\n",
    "# testing_period = 70 # number of days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c77140",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Loop through the time range in increments of testing period\n",
    "# for i in range(training_period, len(X_train) - testing_period, testing_period):\n",
    "    \n",
    "#     # Define the start and end dates for the training and testing data\n",
    "#     start_train_date = X_train.index[i - training_period]\n",
    "#     end_train_date = X_train.index[i - 1]\n",
    "#     start_test_date = X_test.index[i]\n",
    "#     end_test_date = X_test.index[i + testing_period - 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9920e784",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # # Slice the data into the training and testing datasets\n",
    "    # train_df = X_train.loc[start_train_date:end_train_date]\n",
    "    # test_df = X_test.loc[start_test_date:end_test_date]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a374d521",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # # Define the input features and target variable for the AdaBoost model\n",
    "    # X_train = train_df[['SMA_Fast', 'SMA_Slow']].shift()\n",
    "    # y_train = signals_df['Signal'].shift()\n",
    "    # X_test = test_df[['SMA_Fast', 'SMA_Slow']].shift()\n",
    "    # y_test = signals_df['Signal'].shift()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "13cccc38",
   "metadata": {},
   "source": [
    "### Using Alternative mode to see if we can achive higher average score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceda492f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Fit the model to the training data\n",
    "rf_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Use the model to make predictions on the testing data\n",
    "rf_pred = rf_model.predict(X_train_scaled)\n",
    "\n",
    "print(rf_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd99179b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a classification report to evaluate the model using the predictions and testing data\n",
    "rf_testing_report_train = classification_report(y_train, rf_pred)\n",
    "\n",
    "# Print the classification report\n",
    "print(rf_testing_report_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a70a9dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the trained model to predict the trading signals for the testing data.\n",
    "testing_signal_predictions = rf_model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a385db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model's ability to predict the trading signal for the testing data\n",
    "testing_report_test = classification_report(y_test, testing_signal_predictions)\n",
    "\n",
    "# Display the report\n",
    "print(testing_report_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "378a3ae1",
   "metadata": {},
   "source": [
    "Adaboose Model  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e1a9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate the model instance\n",
    "adaboost_model = AdaBoostClassifier()\n",
    "\n",
    "# Fit the model using the training data\n",
    "model = adaboost_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Use the testing dataset to generate the predictions for the new model\n",
    "pred = adaboost_model.predict(X_test_scaled)\n",
    "\n",
    "# Review the model's predicted values\n",
    "print(pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a370aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a classification report to evaluate the model using the predictions and testing data\n",
    "ada_pred = classification_report(y_test, pred)\n",
    "\n",
    "# Print the classification report\n",
    "print(ada_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435ff1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new empty predictions DataFrame:\n",
    "# Create a predictions DataFrame\n",
    "ada_predictions_df = pd.DataFrame(index=X_test.index)\n",
    "\n",
    "# Add the SVM model predictions to the DataFrame\n",
    "ada_predictions_df['Predicted'] = pred\n",
    "\n",
    "# Add the actual returns to the DataFrame\n",
    "ada_predictions_df['Actual Returns'] = indicators_df['Actual Returns']\n",
    "\n",
    "# Add the strategy returns to the DataFrame\n",
    "ada_predictions_df['Strategy Returns'] = ada_predictions_df['Actual Returns'] * pred\n",
    "\n",
    "# Review the DataFrame\n",
    "ada_predictions_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2251f547",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the actual returns versus the strategy returns\n",
    "(1 + ada_predictions_df[['Actual Returns', 'Strategy Returns']]).cumprod().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62bc47ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
